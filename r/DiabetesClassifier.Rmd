---
title: "Symptom Significance in Diabetes Diagnosis"
author: "Gabriela Serrano and JuanCarlos Jimenez"
output: html_notebook
date: April 30, 2022
---
&nbsp;


This is the R programming language script for the final project "Symptom Significance in Diabetes Diagnosis". The project consists of applying a variety of techniques (such as cross-validation, hyperparameter tuning) and binary classification models to a UCL Machine Learning Repository diabetes dataset in order to predict whether a patient has or not the condition based on a set of symptoms. 
&nbsp;

The project will be submitted in fulfillment of the requirements of CSC 597 (Introduction to Statistical Learning with Applications in R) at the University of Miami. 


```{r}
# Load libraries
library(boot)
library(caret)
library(tree)
library(randomForest)
library(e1071)
library(rpart)
```

## Section I: Loading the data
```{r}
# Load the dataset "diabetes_data_upload.csv"
Diabetes <- read.csv("~/Documents/github.git/DiabetesClassifier/data/diabetes_data_upload.csv", stringsAsFactors=TRUE)

# DF Names
names(Diabetes)

# DF Dimensions
dim(Diabetes)

# DF Summary 
summary(Diabetes)

# Have to check for N/A values (missing = FALSE in all instances)
missing = is.na(Diabetes) 
```

## Section II: Data Distribution / Visualization
```{r}
# Age Distribution
histogram(Diabetes$Age, main="Histogram of Age Distribution", xlab="Age", ylab="Percentage", col="grey")

# Sex Distribution
histogram(Diabetes$Sex, main="Histogram of Sex Distribution", xlab="Sex", ylab="Percentage", col="grey")
  
# Save as png
  # Age
  png(file="Age-Distribution.png")
  histogram(Diabetes$Age, main="Histogram of Age Distribution", xlab="Age", ylab="Percentage", col="grey")
  dev.off()
  # Sex
  png(file="Sex-Distribution.png")
  histogram(Diabetes$Sex, main="Histogram of Sex Distribution", xlab="Sex", ylab="Percentage", col="grey")
  dev.off()
```

## Section III: Data Preparation
```{r}
# Set seed - generate same random numbers to reproduce results
set.seed(821)  

# Split data (80:20, training:testing)

  # sample( ) function randomly picks 80% rows from the data set (sampling without replacement)
  dt <- sort(sample(nrow(Diabetes), nrow(Diabetes)*.8))
  # Creates the training dataset with row numbers stored in dt
  train <- Diabetes[dt,] 
  # Creates the testing dataset excluding the row numbers mentioned in dt
  test <- Diabetes[-dt,] 
  
# Train Control definition (method we are going to use for CV)
train_control <- trainControl(method = "cv", number = 20)
```


## Section IV: Validation of classification models: Logistic Regression, Decision Tree, Random Forest, Na誰ve Bayes Classifier

### Logistic Regression K-Fold CV (K=20)
```{r}
# Logistic Regression
cv.log <- train(class ~ ., 
                  data=train, 
                  trControl=train_control, 
                  method="glm", 
                  family=binomial())

summary(cv.log)

# Results
cv.log$results
  
# Variable Importance
var.log <-varImp(cv.log)
var.log
```

### Logistic Regression Performance (fit)
```{r}
# Performance
mod.log <- glm(class ~ ., data=train, family=binomial(link="logit"))
pred.log <- predict(mod.log, newdata=test, type = "response")

# Prepare variables for CM
  # Check length
  length(pred.log)
  # Check contrasts
  contrasts(Diabetes$class)
  # Data input preparation
  probs.log = rep("Negative", 104)
  probs.log[pred.log >0.5] = "Positive"
  probs.log = as.factor(probs.log)

# Confusion Matrix
confusionMatrix(data=probs.log, mode="everything", reference = test$class)
```

### Decision Tree K-Fold CV (K=20)
```{r}
# Cross-Validation
cv.tree = train(class ~ ., 
                  data=train, 
                  method="rpart", 
                  trControl = train_control)

# Results (optimal)
cv.tree

# Plot
plot(cv.tree)

# Results (mean)
mat.data <- c(
  mean(cv.tree$results$cp),
  mean(cv.tree$results$Accuracy),
  mean(cv.tree$results$AccuracySD),
  mean(cv.tree$results$Kappa),
  mean(cv.tree$results$KappaSD)
)

mat <- matrix(mat.data,byrow=FALSE)
columns <-c("Complexity Parameter","Accuracy", "AccuracySD", "Kappa", "KappaSD")
dimnames(mat) <- list(columns, "metrics")
mat
  
# Variable Importance
var.tree <- varImp(cv.tree)
var.tree
```

### Decision Tree Performance (fit)
```{r}
# Performance
mod.tree = tree(class~., data=train)
plot(mod.tree)
text(mod.tree, pretty=0, cex=0.5)

# Prediction for CM
pred.tree = predict(mod.tree, newdata=test, type="class")

# Confusion Matrix
confusionMatrix(data=pred.tree, mode="everything", reference = test$class)
```

### Random Forest K-Fold CV (K=20)
```{r}
# Cross-Validation
cv.rf <-  train(class ~ ., 
                  data=train, 
                  method="rf", 
                  trControl = train_control, tuneLength=15)

# Results
cv.rf

# Plot
plot(cv.rf)
  
# Variable Importance
var.rf <- varImp(cv.rf)
var.rf
```
### Random Forest Performance (default fit)
```{r}
reg.mod.forest <- randomForest(class~., data=train) 

# Prediction for CM
reg.pred.forest <- predict(reg.mod.forest, newdata=test)

# Confusion Matrix 
confusionMatrix(data=reg.pred.forest, mode="everything", reference=test$class)
```


### Random Forest Performance (optimized fit)
```{r}
# Performance
mod.forest <- randomForest(class~., data=train, mtry=9) # ntree=500, nrnodes=77 

# Prediction for CM
pred.forest <- predict(mod.forest, newdata=test)

# Confusion Matrix 
confusionMatrix(data=pred.forest, mode="everything", reference=test$class)
```

### Na誰ve Bayes Classifier K-Fold CV (K=20)
```{r}
# Cross-Validation
cv.nb <-  train(class~ ., 
                  data = train, 
                  method = "naive_bayes", 
                  )

# Results
cv.nb

# Plot
plot(cv.nb)

# Variable Importance
var.nb <- varImp(cv.nb)
var.nb
```

### Na誰ve Bayes Classifier Performance (default fit)
```{r}
reg.mod.nb <- naiveBayes(class~ ., data=train)
 
# Prediction for CM
reg.pred.nb <- predict(reg.mod.nb, newdata=test)

# Confusion Matrix
confusionMatrix(data=reg.pred.nb, mode="everything", reference=test$class)
```


### Na誰ve Bayes Classifier Performance (optimized fit)
```{r}
# Performance
mod.nb <- naiveBayes(class~ ., data=train, laplace=0, usekernel=FALSE, adjust=1)
 
# Prediction for CM
pred.nb <- predict(mod.nb, newdata=test)

# Confusion Matrix
confusionMatrix(data=pred.nb, mode="everything", reference=test$class)
```

## Section V: Analyze Variable Importance (top six)
```{r}
# Want to analyze best predictors for model (check varImp)
varOrder.log = var.log$importance[order(var.log$importance$Overall, decreasing=T), , drop=F]
varOrder.tree = var.tree$importance[order(var.tree$importance$Overall, decreasing=T), , drop=F]
varOrder.rf = var.rf$importance[order(var.rf$importance$Overall, decreasing=T), , drop=F]
varOrder.nb = var.nb$importance[order(var.nb$importance$Positive, decreasing=T), , drop=F]

head.log <- head(varOrder.log, 6)
head.tree <- head(varOrder.tree, 6)
head.rf <- head(varOrder.rf, 6)
head.nb <- data.frame(head(varOrder.nb$Positive, 6), row.names =c("Polyuria","Polydipsia","Sudden.weightloss", "Sex", "Partial.paresis", "Polyphagia"))

colnames(head.nb) <- c("Overall")

# View
par(mfrow=c(1,4))
head.log
head.tree
head.rf
head.nb

```

